In my previous video, I showed how most advanced systems in natural language processing use recurrent neural network or RNNs. RNNs process words 1 by one and this makes them slow, especially for long sentences. And they struggle to capture relationships between words far apart, making it hard to understand how different parts of a sentence relate to each other. In this video you'll learn how the transformer architecture changed the game using its attention mechanism. With this foundational knowledge will be able to understand and value various emerging technologies and players in the ever growing AI landscape. The power of transformer architecture lies in its ability to understand and learn the relevance and context of all words in the sentence. Let's consider this sentence the animal didn't cross the street because it was too tired. Unlike traditional models that focus only on neighboring words, Transformer understands the relationships between every word in a sentence. The transformer applies attention weights to these relationships, learning the importance of each word to every word regardless of their position within the input. This gives the algorithm the ability to learn who is trying to cross the street, if the street was crossed, and if it's even relevant to the wider context of the story. These attention weights are learned during LLM training, which you will learn more about in my future videos in this series. Now let's try to understand the attention mechanism by drawing an attention map of our example sentence. This diagram here is called an attention map and can be useful to illustrate the attention weights between each word and every other word. In this example you can see that the word animal is strongly connected with or paying attention to the word street and and the word ate. This is called self attention and the ability to learn attention in this way across the whole input significantly improves the model's ability to encode language. So when the model is trying to figure out what the word it refers to, it uses attention. It calculates an attention score between it and every other word in the sentence. For example, it will give a high score to the word animal because it likely refers to the animal. It might assign a moderate score maybe to street because animal can cross streets and assign low scores to words like the because and to because these are less relevant to what it refers to. And finally, the model creates a new representation of the word it that is a weighted combination based on these attention scores. This helps the model understand context and resolve any ambiguities, accurately determining what pronouns like it, he or she refers to and also capturing how words far apart in the sentence can relate to each other. Now, note that this example about attention score is very simplified Way to think about it. In reality, the transformer has multiple attention heads, each focusing on different aspects and relationships between words. The score calculation is not simple word similarity, it uses complex mathematical functions for better results. Now that you have learned a fundamental aspect of the transformer architecture self attention, let's provide an overview of how the model operates at a high level. This is the original published transformer architecture derived from the original paper. Attention is all you need and here is a simplified high level diagram of the same transformer architecture for you to understand its essential and important parts easily. As you can see, there are two main input lines from the bottom one to the encoder and one to the decoder. The input lines have distinct purposes. The encoder processes the original input, while through the decoder input the previously generated words are fed back into the decoder. By feeding back the previously generated words, the decoder ensures that the output sentence is grammatically correct and follows a logical sequence. Also note that the decoder's output doesn't directly connect back to the main input line in the diagram. Instead, the predicted word is explicitly copied and used as the new input for the next step and this creates a loop within the decoder, allowing it to build context. The encoder block processes the input sentence where it must first tokenize the words. Simply put, this converts the word into tokens and then to numbers. You can choose from the multiple tokenization methods which we have discussed in my previous video. Let's go back with the simple word tokenizer here. Now that your input is represented as numbers, we pass it to the embedding layer. This layer is a high dimensional space where each token is represented as a vector and occupies a unique location within that space, encoding the meaning and context of individual tokens in the input sequence. Now, I have covered embeddings in my previous video, but we will also look at it in more detail in future videos. To understand word embeddings in a simplified way, imagine each word being represented by a point in a three dimensional space. Similar to plotting locations on a map. This space allows you to visualize the relationships between words. Words with similar meanings tend to be positioned closer together in this space, while the actual embedding space has many more than three dimensions. The simplified example illustrates how we can calculate the distance between words using mathematical operations. This ability to quantify word similarity is crucial for tasks like machine translation and text categorization. When feeding words into the encoder or decoder, we add positional encoding to their respective word embeddings. This helps the model understand the order of the words as transformers. Don't process them strictly sequentially like older models. Next, the combined vectors or the word embedding plus the position enter to the self attention layer. Here, the model analyzes how different words in the input sentence relate to each other. This process learns attention weights, which indicates how much each word should pay attention to all the other words in the sentence, boosting those that are more relevant to capture different aspects of the language. Transformer uses multi headed self attention. This means the model learns multiple sets of attention weights in parallel. While it's tempting to think one head might focus on animals, another on activities such as crossing the street, etc. The exact roles of these heads develop organically during training, and we don't specify them upfront. The attention mechanism is within the encoder decoder module of the Transformer architecture. It plays a crucial role in both the encoder and decoder. Now, the encoder's job is to create a rich representation of the English sentence. Think of it like a deep analysis of the sentences that focus on how words relate to each other. For example, in our sentence the animal didn't cross the street because it was too tired. Here is how the encoder might build a rich representation. In layer one it might first understand the basic connections. It will identify the basic relationships like animal is the subject of did not cross, or sweet is what the animal didn't cross. Or maybe the word tired describes the word it. And probably in layer two it gets a deeper understanding. It starts to understand the word, it likely refers to the word animal and it might begin picking up the reason such as didn't cross and the word tired are connected. And maybe in the layer 3 and beyond it gets more nuances. For example, it understands the negative sentiment that it didn't cross, or or it might identify a slight emphasis on the reason with the words like because and to. By rich representation, it means that instead of just seeing the words in a sequence, the encoder generates an understanding that includes the parts of speech such as noun, verbs, adjectives, etc. It also understands how words relate to one another within the sentence's structure and hints about the overall meaning of the sentence that animal is not crossing that street, but due to a fatigue and also the entire context. That is how the word ate is heavily influenced by the context of the sentence, resolving the ambiguity of what it refers to. And this representation is what the decoder leverages. This helps the decoder select appropriate French words, not just their literal translations. It ensures the French sentence has the correct structure and aims to preserve the overall sentiment of the original sentence. Note that this is a simplified way to think about it, but in reality the encoder's representation is a complex set of numbers that are difficult for humans to interpret directly. Now let's see how the decoder processes the information. Notice that the decoder has two input lines. The main input line is a standalone line responsible for feeding the following to the decoder. It is initially set to the start token and in the subsequent steps the previously generated output words are fed back through the main input line. The encoder decoder attention line is a separate line that connects the encoder to the decoder, allowing the decoder to access the encoder's representation of the input sequence. It's not a direct feed of words, but rather a transfer of information through attention. Remember, our goal here is to translate the animal didn't cross the street because it was too tight into French. Let's now let's see it step by step. So as a starting point in step one, in the transformer decoder, the start token act as a special signal that tells the model to begin generating the output sequence. It helps the decoder understand the context and initiate the translation process. Just like hitting the play button on the music player, the start token indicates the decoder should start generating the output. And during attention, the decoder pays attention to this token itself and the entire encoder representation of the English sentence. And in step two, it does the output prediction, which is based on the input and the encoder information. The decoder predicts the word le french for the word the as the first word. And in attention it focus would be on the words like the and animal in the English sentence to find the right French equivalent. And now during step three, the input to the decoder is has the start token and the word lay. And during attention, the decoder self attention ensures that lay makes sense in the French sentence. So far, while the encoder attention is still heavily focused on understanding the original English sentence, selecting the right French word to match animal and the output prediction predicts chat, which is French for cat. And step four and beyond the this process continues with the decoder's input growing from start to late chat and so on, and the attention shifts as the French translation progresses, focusing on both previous French words and the crucial parts of the encoder's English representation. It keeps predicting words until it outputs ends with a special end token. Now the decoder's ability to select the right French words heavily depends on the rich representation the encoder provided. The decoder's attention shifts as the French sentence is built. At first it's heavily focused on the English, but as the translation progresses, it needs to ensure the French being generated is also grammatically sound. Most importantly, the decoder isn't just translating word by word. It's focused on producing a French sentence that captures the overall meaning and intent of the original English sentence. The encoder and decoder typically do not work in perfect parallel. The encoder processes the entire input sequence first to create its representation. Then the decoder uses this representation and its own internal state to generate the output sequence one word at a time. While certain calculations within the encoder and decoder might be paralyzed on hardware for efficiency, they conceptually operate in a sequential manner for most tasks. Finally, the encoder decoder structure is not limited to machine translation. It equally applies to text summarization, wherein encoder processes the full text and the decoder generates a condensed summary in question answering, the encoder processes the context, such as a passage or document, and the decoder generates the answer to a specific question. And for text generation, the encoder might process a short prompt or initial seed text, and the decoder generates creative text formats like poems or quotes. In future videos, we'll dive deeper into the training process of large language models built on the transformer architecture.